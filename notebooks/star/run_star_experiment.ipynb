{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import os\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.data.STAR.star import STARDataset\n",
    "\n",
    "if not os.path.exists('star_results'):\n",
    "    os.makedirs('star_results')\n",
    "\n",
    "path_star_dataset = \"../../src/data/STAR/STAR_Students.csv\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"'force_all_finite' was renamed to 'ensure_all_finite'\",\n",
    "    category=FutureWarning,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import (\n",
    "    LogisticRegressionCV,\n",
    "    RidgeCV,\n",
    ")\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from src.randomization_aware.combine_cate import CATECombiner\n",
    "from src.randomization_aware.learners import (\n",
    "    DRLearner,\n",
    "    QuasiOptimizedLearner,\n",
    ")\n",
    "from src.baselines.asaiee import AsaieeCATE\n",
    "from src.baselines.ksp import KSPCATE\n",
    "from src.baselines.pooling import TLearnerPooling\n",
    "from src.baselines.trial_only import TrialCATE\n",
    "from econml.metalearners import TLearner\n",
    "\n",
    "\n",
    "crossfit_folds = 2\n",
    "\n",
    "\n",
    "alphas = np.logspace(-2,2,25)\n",
    "regressor_cate = lambda: RidgeCV(alphas=alphas)\n",
    "regressor_outcome = lambda: HistGradientBoostingRegressor(max_depth=3, min_samples_leaf=5, max_iter=100)\n",
    "study_classifier = lambda: LogisticRegressionCV(\n",
    "    max_iter=1000, Cs=[1 / a for a in [0.1, 1.0, 10.0, 100.0]], cv=2, solver=\"liblinear\"\n",
    ")\n",
    "\n",
    "cate_estimator_tlearner = lambda: TLearner(models=regressor_outcome())\n",
    "\n",
    "\n",
    "def get_drlearner_star(propensity_score):\n",
    "    return DRLearner(\n",
    "        propensity_score=propensity_score,\n",
    "        regressor_cate=regressor_cate(),\n",
    "        regressor_control=regressor_outcome(),\n",
    "        regressor_treated=regressor_outcome(),\n",
    "        crossfit_folds=crossfit_folds,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_quasioptimized_star(propensity_score):\n",
    "    return QuasiOptimizedLearner(\n",
    "        propensity_score=propensity_score,\n",
    "        regressor_cate=regressor_cate(),\n",
    "        regressor_control=regressor_outcome(),\n",
    "        regressor_treated=regressor_outcome(),\n",
    "        study_classifier=study_classifier(),\n",
    "        crossfit_folds=crossfit_folds,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_quasioptimized_star_unweighted(propensity_score):\n",
    "    return QuasiOptimizedLearner(\n",
    "        propensity_score=propensity_score,\n",
    "        regressor_cate=regressor_cate(),\n",
    "        regressor_control=regressor_outcome(),\n",
    "        regressor_treated=regressor_outcome(),\n",
    "        study_classifier=study_classifier(),\n",
    "        crossfit_folds=crossfit_folds,\n",
    "        remove_study_weighting=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_combined_star(propensity_score, n_splits_cv=10):\n",
    "    return CATECombiner(\n",
    "        propensity_score=propensity_score,\n",
    "        cate_learner_1=get_drlearner_star(propensity_score),\n",
    "        cate_learner_2=get_quasioptimized_star(propensity_score),\n",
    "        n_splits_cv=n_splits_cv\n",
    "    )\n",
    "\n",
    "\n",
    "def get_asaiee_star(propensity_score):\n",
    "    return AsaieeCATE(\n",
    "        propensity_score=propensity_score,\n",
    "        regressor_cate=regressor_cate(),\n",
    "        regressor_control=regressor_outcome(),\n",
    "        regressor_treated=regressor_outcome(),\n",
    "        crossfit_folds=crossfit_folds,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ksp_star(propensity_score):\n",
    "    return KSPCATE(\n",
    "        propensity_score,\n",
    "        cate_estimator=cate_estimator_tlearner(),\n",
    "        bias_correction_model=RidgeCV(alphas=alphas),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_pooling_star(propensity_score=None):\n",
    "    return TLearnerPooling(\n",
    "        regressor_control=regressor_outcome(),\n",
    "        regressor_treated=regressor_outcome(),\n",
    "        study_classifier=study_classifier(),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_tlearner_star(propensity_score=None):\n",
    "    return TrialCATE(cate_estimator=cate_estimator_tlearner())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_sample_sizes_independent(\n",
    "    target_fraction_of_main_loc, eval_fraction_of_target, target_label\n",
    "):\n",
    "    dgp = STARDataset(path_star_dataset, target_label=target_label)\n",
    "\n",
    "    max_n1 = 0\n",
    "    for n1 in range(1, 10000, 10):  # Increment n1 in steps of 100\n",
    "        try:\n",
    "            dgp.sample(\n",
    "                n1,\n",
    "                1,\n",
    "                target_fraction_of_main_loc=target_fraction_of_main_loc,\n",
    "                eval_fraction_of_target=eval_fraction_of_target,\n",
    "            )\n",
    "            max_n1 = n1\n",
    "        except Exception as e:\n",
    "            print(f\"Error for n1={n1}: {e}\")\n",
    "            break  # Stop increasing n1 if an error occurs\n",
    "\n",
    "    max_n0 = 0\n",
    "    for n0 in range(1, 10000, 10):  # Increment n0 in steps of 100\n",
    "        try:\n",
    "            dgp.sample(\n",
    "                1,\n",
    "                n0,\n",
    "                target_fraction_of_main_loc=target_fraction_of_main_loc,\n",
    "                eval_fraction_of_target=eval_fraction_of_target,\n",
    "            )\n",
    "            max_n0 = n0\n",
    "        except Exception as e:\n",
    "            print(f\"Error for n0={n0}: {e}\")\n",
    "            break  # Stop increasing n0 if an error occurs\n",
    "\n",
    "    return max_n1, max_n0\n",
    "\n",
    "\n",
    "target_fraction_of_main_loc = 1.0\n",
    "eval_fraction_of_target = 0.5\n",
    "get_max_sample_sizes_independent(\n",
    "    target_fraction_of_main_loc, eval_fraction_of_target, target_label=\"urban\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d29a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"DR-learner\": get_drlearner_star,\n",
    "    \"QR-learner\": get_quasioptimized_star,\n",
    "    \"QR-learner (unweighted)\" : get_quasioptimized_star_unweighted,\n",
    "    \"Combined learner\": partial(get_combined_star, n_splits_cv=10),\n",
    "    \"Asaiee et al. (2023)\": get_asaiee_star,\n",
    "    \"Kallus et al. (2018)\": get_ksp_star,\n",
    "    \"Pooled T-learner\": get_pooling_star,\n",
    "    \"T-learner\": get_tlearner_star,\n",
    "}\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"timestamp: {timestamp}\")\n",
    "iterations = 100\n",
    "n1_list = [100, 200, 300, 400, 500, 600, 700]  \n",
    "n0_list = [1000]  \n",
    "fraction_rural_list = [1.0]\n",
    "target_label = \"rural\"\n",
    "covar_to_drop = [\n",
    "    \"g1surban\",\n",
    "]\n",
    "rows = []\n",
    "\n",
    "full_covar_list = [\n",
    "    \"g1surban\",\n",
    "    \"gender\",\n",
    "    \"race\",\n",
    "    \"birthmonth\",\n",
    "    \"birthday\",\n",
    "    \"birthyear\",\n",
    "    \"gkfreelunch\",\n",
    "    \"g1tchid\",\n",
    "    \"g1freelunch\",\n",
    "]\n",
    "\n",
    "for dropped_covar in covar_to_drop:\n",
    "    if dropped_covar is None:\n",
    "        covar_list = full_covar_list\n",
    "    else:\n",
    "        if isinstance(dropped_covar, list):\n",
    "            if all(covar in full_covar_list for covar in dropped_covar):\n",
    "                covar_list = [\n",
    "                    covar for covar in full_covar_list if covar not in dropped_covar\n",
    "                ]\n",
    "            else:\n",
    "                missing = [\n",
    "                    covar for covar in dropped_covar if covar not in full_covar_list\n",
    "                ]\n",
    "                raise ValueError(f\"{missing} not found in full_covar_list\")\n",
    "        elif dropped_covar in full_covar_list:\n",
    "            covar_list = [covar for covar in full_covar_list if covar != dropped_covar]\n",
    "        else:\n",
    "            raise ValueError(f\"{dropped_covar} not found in full_covar_list\")\n",
    "    dgp = STARDataset(\n",
    "        path_star_dataset,\n",
    "        cat_covar_columns=covar_list,\n",
    "        target_label=target_label,\n",
    "    )\n",
    "    propensity_score_rct = dgp.get_propensity_score()\n",
    "    for fraction_rural in fraction_rural_list:\n",
    "        for n1 in n1_list:\n",
    "            for n0 in n0_list:\n",
    "                print(f\"dropped_covar = {dropped_covar}, n1 = {n1}; n0 = {n0}\")\n",
    "                for i in tqdm(range(iterations)):\n",
    "\n",
    "                    X_train, S_train, A_train, Y_train, X_eval, gt_adjusted_ite_eval = (\n",
    "                        dgp.sample(\n",
    "                            n1,\n",
    "                            n0,\n",
    "                            target_fraction_of_main_loc=fraction_rural,\n",
    "                            eval_fraction_of_target=eval_fraction_of_target,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    for method_name, method_func in methods.items():\n",
    "\n",
    "                        estimator = method_func(propensity_score_rct)\n",
    "\n",
    "                        try:\n",
    "                            estimator.fit(X_train, S_train, A_train, Y_train)\n",
    "                            predictions = estimator.predict(X_eval)\n",
    "\n",
    "                            assert predictions.shape == gt_adjusted_ite_eval.shape\n",
    "                            rmse = np.sqrt(\n",
    "                                np.mean((gt_adjusted_ite_eval - predictions) ** 2)\n",
    "                            )\n",
    "                            abs_bias = np.mean(\n",
    "                                np.abs(gt_adjusted_ite_eval - predictions)\n",
    "                            )\n",
    "                            var = np.var(predictions)\n",
    "                            rows.append(\n",
    "                                {\n",
    "                                    \"i\": i,\n",
    "                                    \"n1\": n1,\n",
    "                                    \"n0\": n0,\n",
    "                                    \"dropped_covar\": (\n",
    "                                        dropped_covar\n",
    "                                        if dropped_covar is not None\n",
    "                                        else \"None dropped\"\n",
    "                                    ),\n",
    "                                    \"fraction_rural\": fraction_rural,\n",
    "                                    \"target_label\": target_label,\n",
    "                                    \"method\": method_name,\n",
    "                                    \"rmse\": rmse,\n",
    "                                    \"abs_bias\": abs_bias,\n",
    "                                    \"var\": var,\n",
    "                                }\n",
    "                            )\n",
    "                        except Exception as e:\n",
    "                            rows.append(\n",
    "                                {\n",
    "                                    \"i\": i,\n",
    "                                    \"n1\": n1,\n",
    "                                    \"n0\": n0,\n",
    "                                    \"dropped_covar\": (\n",
    "                                        dropped_covar\n",
    "                                        if dropped_covar is not None\n",
    "                                        else \"None dropped\"\n",
    "                                    ),\n",
    "                                    \"fraction_rural\": fraction_rural,\n",
    "                                    \"target_label\": target_label,\n",
    "                                    \"method\": method_name,\n",
    "                                    \"error\": str(e),\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "                        # Save results in a CSV file with a timestamp\n",
    "                        results_df = pd.DataFrame(rows)\n",
    "                        results_df.to_csv(\n",
    "                            f\"star_results/experiment_{timestamp}.csv\", index=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybnesian import RCoT, LinearCorrelation\n",
    "\n",
    "dgp = STARDataset(\n",
    "    path_star_dataset,\n",
    "    cat_covar_columns=[\n",
    "        \"gender\",\n",
    "        \"race\",\n",
    "        \"birthmonth\",\n",
    "        \"birthday\",\n",
    "        \"birthyear\",\n",
    "        \"gkfreelunch\",\n",
    "        \"g1tchid\",\n",
    "        \"g1freelunch\",\n",
    "    ],\n",
    "    target_label='rural',\n",
    ")\n",
    "\n",
    "# Sample\n",
    "X_train, S_train, A_train, Y_train, _, _ = dgp.sample(\n",
    "    2800,\n",
    "    1400,\n",
    "    target_fraction_of_main_loc=1.0,\n",
    "    eval_fraction_of_target=0.001\n",
    ")\n",
    "\n",
    "\n",
    "A_df = pd.DataFrame(A_train, columns=['A'])\n",
    "S_df = pd.DataFrame(S_train, columns=['S'])\n",
    "Y_df = pd.DataFrame(Y_train, columns=['Y'])\n",
    "X_names = [f\"X_{i}\" for i in range(X_train.shape[1])]\n",
    "X_df = pd.DataFrame(X_train, columns=X_names)\n",
    "\n",
    "data_df = pd.concat([A_df, S_df, Y_df, X_df], axis=1)\n",
    "\n",
    "test1 = RCoT(data_df)\n",
    "print(test1.pvalue('Y', 'S', X_names + ['A']))\n",
    "\n",
    "\n",
    "test2 = LinearCorrelation(data_df)\n",
    "print(test2.pvalue('Y', 'S', X_names + ['A']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
